---
layout: post
title:  "My Take on Jaron Lanier's Ten Arguments for Deleting Your Social Media Accounts Right Now"
date:   2018-09-26 00:00:00 -0600
categories: jekyll update
---

In [Ten Arguments For Deleting Your Social Media Accounts Right Now](http://www.jaronlanier.com/tenarguments.html) Jaron Lanier presents a list of reasons why people should get rid of their accounts on social media. While the title might suggest one of those dubious clickbait articles (now also in book format), luckily, the book only shares few similarities with such content: it is relatively short and has a simple structure. This actually helps a lot to bring his key points across and makes the book accessible to a wider audience. Also he repeats his main message, though in different variations, over and over again: do it, go ahead, delete your social media accounts! But that is about it when it comes to clickbait similarities.

## Behavior Modification Empires
Why does social media undermine the truth, making you into an asshole, and even hates your soul as Lanier delicately puts it? His first argument  already describes the root of the problem. Social media companies earn money by selling your attention, mostly this is attention for advertisements. By keeping you longer on their platforms, they can sell more of your attention and make more money. So far, so simple. To determine what makes you stay longer, social media platforms collect every piece of information about you and your behavior (how long do you stay, what do you look at, what do you message your friends etc.) and apply an algorithm that comes up with a personalized scheme for every user that makes her or him stay as long as possible. While this might sound a little abstract, lets consider two examples: the algorithms might recognize that sport news will make you leave the platform earlier and, hence, shows you fewer articles on sport in the future. Or many people with the same interests as you respond positively to regular notifications via e-mail. Then it is likely you will also receive such mails. While in reality this algorithm might be much more complex, this is how Lanier describes its basic functioning. He even claims that the font size is adapted in an attempt to make users stay.

To put it in a nutshell, all your interactions with social media platforms are closely monitored and this information is used by an black-box algorithm to manipulate you into staying longer. Techniques that worked for similar persons plus some random changes are tested on you and, whenever they show a positive effect, find their way into your *personalized social media feed*.  Already feeling trapped into some kind of lab rat experiment? That is also Lanier's view of these methods. Another idea of him is to get rid of the term social media and install call these practices by what they are: *behavior modification empires*.

## Separated Realities

Letting such behavior modification empires dominate our online life has serious consequences that Lanier deals with in the remaining nine arguments. One of the most obvious is probably *separated realities*. Since a key ingredient of the behavior modification is the personalized experience, every user has an individual news feed with different articles on top and custom suggestions of what might interest her or him. Moreover, certain posts will be kept completely hidden from some persons, because the algorithm determined they are likely to make them leave. I think a fact acknowledged by too few people. As a consequence, our online experience, the posts we see, the people we interact with, the articles we read, can highly diverge. Lanier uses a vivid example of vaccine critics that consider immunization evil. When these individuals showed him their news feeds, it got understandable how these attitudes arose. Apparently the algorithm decided that it is beneficial to confront these individuals with tons of scary fake content about vaccinations to engage them more with the platform. Articles that people with different attitudes towards vaccination probably will never see in their feeds. This is also a good example of the filter bubble concept. Lanier argues that is is easier to manipulate people when they are clustered into groups with similar interests that will receive the same content. As a consequence of separated realities, he states "the version of the world you are seeing is invisible to the people who misunderstand you and vice-versa".

## Rewarding the Extremes

Another direct consequence of the methods applied by behavior modification empires is that every content is subject to a competition on how much it encourages users to interact with the platform. Which post or which tweet will arouse the biggest attention that ultimately will make users stay longer? Jaron Lanier argues that this leads to a battle about who gains the biggest attention and boils down this mechanism to a simple formula "with nothing else to seek but attention, ordinary people tend to become assholes, because the biggest assholes get the most attention". He elaborates much more on his personal experiences with trolling and his view about the social model behind this behavior. For me the key point is that by selecting content mainly based on its potential for attention acquisition *rewards the extremes*, because it is often more emotionally engaging. I think this argument also rings a bell when thinking about the social media strategies of Trump or right-wing populists in Europe.

## Amplification of Negative Emotions

Another interesting effect that Lanier discusses is the *amplification of negative emotions*. As pointed out above, the algorithm will experiment with different types of content to identify its potential to make you engage with the platform. Now, he argues that content causing negative emotions often turns out to be more effective during these experiments on you: "negative emotions such as fear and anger dwell up more easily and dwell in us longer than positive ones". Simply put, by presenting you posts, news, and pictures that make you feel sad, you are more likely to stay longer on the platform. A sinister side-effect of applying such adaptive algorithms for automatic behavior modification. Lanier defends the algorithm creators with their original intention to just identify personalized content that engages people with the platform. I disagree with him. I think the creators should held responsible if they do not stop such practices or at least inform the affected individuals. In addition to his description of the amplification of negative emotions, there is a full argument "social media is making you unhappy" dealing with more broadly acknowledged consequences of social media such as trolling and the comparison to unreasonable high standards.

Jaron Lanier touches on several other important problems with today's social media platforms such as fake users and uncontrollable contextualization and discusses the political and economical consequences. As an silicon valley insider he can offer interesting insights and the book contains plenty of online resources and scientific papers to justify his reasoning that I omitted in this post. When it comes to solutions, Lanier has two suggestions. First, the problem should be defined as accurately as possible to carve it out properly. In his opinion it is not a collective technological problem, but it is the business model of manipulating the behavior of people to sell their attention that must be put to an end (also well described by [Aral Balkan](https://2018.ar.al/notes/the-nature-of-the-self-in-the-digital-age/)). Second, just try it and delete your social media account and experience the effects this will have on you.